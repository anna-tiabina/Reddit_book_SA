{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e77522-37f8-4213-a706-bdd4893e538e",
   "metadata": {},
   "source": [
    "# Testing GPT-2 fine-tuned on SST-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e3c58a-700f-4af3-bc7b-811a564c48f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e74817c-c1de-4a1e-ab62-8dfe93aaecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"michelecafagna26/gpt2-medium-finetuned-sst2-sentiment\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617123f9-2dc7-4a1a-8f87-8995668c801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = load_dataset(\"csv\", data_files=\"books_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22309957-612b-420e-8cb2-5fe49b0a19dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bde10f5-4853-4a23-bf7d-3199c65c94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(\"michelecafagna26/gpt2-medium-finetuned-sst2-sentiment\").to(device)\n",
    "model.config.pad_token_id = model.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b9e9015-0dd0-4a7a-8f4b-ba611bd091d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0\n",
      "Processing 2\n",
      "Processing 4\n",
      "Processing 6\n",
      "Processing 8\n",
      "Processing 10\n",
      "Processing 12\n",
      "Processing 14\n",
      "Processing 16\n",
      "Processing 18\n",
      "Processing 20\n",
      "Processing 22\n",
      "Processing 24\n",
      "Processing 26\n",
      "Processing 28\n",
      "Processing 30\n",
      "Processing 32\n",
      "Processing 34\n",
      "Processing 36\n",
      "Processing 38\n",
      "Processing 40\n",
      "Processing 42\n",
      "Processing 44\n",
      "Processing 46\n",
      "Processing 48\n",
      "Processing 50\n",
      "Processing 52\n",
      "Processing 54\n",
      "Processing 56\n",
      "Processing 58\n",
      "Processing 60\n",
      "Processing 62\n",
      "Processing 64\n",
      "Processing 66\n",
      "Processing 68\n",
      "Processing 70\n",
      "Processing 72\n",
      "Processing 74\n",
      "Processing 76\n",
      "Processing 78\n",
      "Processing 80\n",
      "Processing 82\n",
      "Processing 84\n",
      "Processing 86\n",
      "Processing 88\n",
      "Processing 90\n",
      "Processing 92\n",
      "Processing 94\n",
      "Processing 96\n",
      "Processing 98\n"
     ]
    }
   ],
   "source": [
    "logits_list = []\n",
    "data = dataset_test['train']['body']\n",
    "batch_size = 2\n",
    "\n",
    "for start in range(0, len(data), batch_size):\n",
    "    print(\"Processing \" + str(start))\n",
    "    batch = data[start:start + batch_size]\n",
    "    # tokenize all first?\n",
    "    inputs = tokenizer(batch, truncation=True, return_tensors=\"pt\", padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        logits_list.append(model(**inputs).logits)\n",
    "logits = torch.cat(logits_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90bf008d-7451-4263-8611-0b14cd42f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_accuracy = evaluate.load(\"accuracy\")\n",
    "load_f1 = evaluate.load(\"f1\")\n",
    "labels = dataset_test['train']['label']\n",
    "predictions = np.argmax(logits.data.cpu().numpy(), axis=-1)\n",
    "accuracy = load_accuracy.compute(predictions=predictions, references=labels)\n",
    "f1 = load_f1.compute(predictions=predictions, references=labels)\n",
    "metrics = {\"accuracy\": accuracy, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01d6e681-0def-4c05-8cc7-429234a38c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': {'accuracy': 0.78}, 'f1': {'f1': 0.8333333333333334}}\n"
     ]
    }
   ],
   "source": [
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998a486f-15c0-4651-a8cc-4d2a0147f6cb",
   "metadata": {},
   "source": [
    "## The accuracy is 0.78, while the F1-score is 0.8333333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818ecd1-2954-4520-94fc-bf217df0dd95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9509734c-7beb-4526-8a47-450aa8c77f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcfcdcb-20ac-4cbb-9da5-ce98f482ca62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
